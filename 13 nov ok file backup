import torch
import cv2
import RPi.GPIO as GPIO
import numpy as np
import os
import json
import time
from flask import Flask, Response
import threading

# ---------------- GPIO Setup ----------------
GPIO.setmode(GPIO.BCM)
GPIO_PIN = 27
GPIO.setup(GPIO_PIN, GPIO.OUT)
GPIO.output(GPIO_PIN, GPIO.HIGH)
print("‚úÖ GPIO 27 initialized (HIGH = no human detected)")

# ---------------- YOLOv5 Setup ----------------
model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True)
model.conf = 0.4
print("‚úÖ YOLOv5n model loaded on CPU")

# ---------------- Flask Web Stream Setup ----------------
app = Flask(__name__)
output_frame = None
lock = threading.Lock()

def generate():
    global output_frame, lock
    while True:
        with lock:
            if output_frame is None:
                continue
            (flag, encodedImage) = cv2.imencode(".jpg", output_frame)
            if not flag:
                continue
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + bytearray(encodedImage) + b'\r\n')

@app.route("/video")
def video_feed():
    return Response(generate(), mimetype="multipart/x-mixed-replace; boundary=frame")

def run_flask():
    app.run(host="0.0.0.0", port=8080, debug=False, threaded=True)

threading.Thread(target=run_flask, daemon=True).start()
print("üåê Stream started: open http://<your_pi_ip>:8080/video on phone/laptop")

# ---------------- Geofence Save/Load ----------------
FENCE_FILE = "/home/root1/fence.json"

def save_fence(points):
    try:
        with open(FENCE_FILE, "w") as f:
            json.dump(points, f)
        print("üíæ Fence saved.")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not save fence: {e}")

def load_fence():
    if os.path.exists(FENCE_FILE):
        try:
            with open(FENCE_FILE, "r") as f:
                data = json.load(f)
            if isinstance(data, list):
                print("‚úÖ Loaded saved fence.")
                return data
        except Exception as e:
            print(f"‚ö†Ô∏è Could not load fence: {e}")
    return []

# ---------------- Fence & Camera Setup ----------------
drawing = False
fence_points = load_fence()
temp_points = []

cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
if not cap.isOpened():
    print("‚ùå Camera not opened")
    GPIO.cleanup()
    exit()

print("üé• Camera ready. Press 'f' to draw fence, 'r' to reset, 'q' to quit.")

def mouse_callback(event, x, y, flags, param):
    global drawing, temp_points, fence_points
    if drawing and event == cv2.EVENT_LBUTTONDOWN:
        temp_points.append((x, y))
        print(f"üü£ Point added: {x}, {y}")

cv2.namedWindow("YOLOv5 Human Detection")
cv2.setMouseCallback("YOLOv5 Human Detection", mouse_callback)

last_state = None
last_change_time = time.time()

# ---------------- Main Loop ----------------
try:
    frame_count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            print("‚ö†Ô∏è Frame not captured")
            break

        frame_count += 1
        # üü¢ Skip 1 frame (process every 2nd frame)
        if frame_count % 2 != 0:
            with lock:
                output_frame = frame.copy()
            continue

        # Draw fence (violet)
        if len(fence_points) > 1:
            cv2.polylines(frame, [np.array(fence_points, np.int32)], True, (255, 0, 255), 2)
            for (x, y) in fence_points:
                cv2.circle(frame, (x, y), 4, (255, 0, 255), -1)
        if drawing and len(temp_points) > 1:
            cv2.polylines(frame, [np.array(temp_points, np.int32)], False, (255, 0, 255), 2)

        # Run YOLO
        results = model(frame)
        detections = results.pandas().xyxy[0]
        humans = detections[detections['name'] == 'person']
        count = 0

        for _, row in humans.iterrows():
            x1, y1, x2, y2 = map(int, [row['xmin'], row['ymin'], row['xmax'], row['ymax']])
            cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)

            if len(fence_points) > 2 and cv2.pointPolygonTest(np.array(fence_points, np.int32), (cx, cy), False) >= 0:
                count += 1
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, "Inside Fence", (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            else:
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)

        detected = count > 0
        current_state = GPIO.LOW if detected else GPIO.HIGH

        if current_state != last_state:
            last_change_time = time.time()
            last_state = current_state
        elif time.time() - last_change_time >= 2:
            GPIO.output(GPIO_PIN, current_state)

        cv2.putText(frame, f"Humans Inside: {count}", (10, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)

        with lock:
            output_frame = frame.copy()  # Send frame to network stream

        cv2.imshow("YOLOv5 Human Detection", frame)
        key = cv2.waitKey(1) & 0xFF

        if key == ord('f'):
            drawing = True
            temp_points = []
            print("üü£ Draw new fence by clicking points on video window.")
        elif key == 13 and drawing:
            fence_points = temp_points.copy()
            drawing = False
            save_fence(fence_points)
            print("‚úÖ Fence saved & finalized.")
        elif key == ord('r'):
            fence_points = []
            temp_points = []
            drawing = False
            save_fence(fence_points)
            print("üîÅ Fence reset.")
        elif key == ord('q'):
            break

finally:
    cap.release()
    cv2.destroyAllWindows()
    GPIO.output(GPIO_PIN, GPIO.HIGH)
    GPIO.cleanup()
    print("‚öôÔ∏è Clean exit and GPIO released.")
