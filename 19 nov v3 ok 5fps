import cv2
import lgpio
import numpy as np
import os
import json
import time
from ultralytics import YOLO
from flask import Flask, Response
import threading

# ---------------- OpenCL (use GPU for OpenCV ops if available) ----------------
cv2.ocl.setUseOpenCL(True)
print("OpenCL available:", cv2.ocl.haveOpenCL())

# ---------------- GPIO Setup (Raspberry Pi 5) ----------------
GPIO_PIN = 27
chip = lgpio.gpiochip_open(0)
lgpio.gpio_claim_output(chip, GPIO_PIN)
lgpio.gpio_write(chip, GPIO_PIN, 1)   # HIGH = no human detected
print("‚úÖ GPIO 27 initialized (HIGH = no human detected)")

# ---------------- YOLOv8n Model ----------------
print("‚è≥ Loading YOLOv8n model (this may download weights)...")
model = YOLO("yolov8n.pt")   # compact & balanced
print("‚úÖ YOLOv8n loaded")

# ---------------- Flask MJPEG stream ----------------
app = Flask(__name__)
output_frame = None
lock = threading.Lock()

def generate():
    global output_frame
    while True:
        with lock:
            if output_frame is None:
                continue
            ok, encoded = cv2.imencode(".jpg", output_frame)
            if not ok:
                continue
        yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + bytearray(encoded) + b'\r\n')

@app.route("/video")
def video_feed():
    return Response(generate(), mimetype="multipart/x-mixed-replace; boundary=frame")

threading.Thread(target=lambda: app.run(host="0.0.0.0", port=8080, debug=False, threaded=True),
                 daemon=True).start()
print("üåê Stream started: http://<your_pi_ip>:8080/video")

# ---------------- Geofence Save/Load ----------------
FENCE_FILE = "/home/root1/fence.json"

def save_fence(points):
    try:
        with open(FENCE_FILE, "w") as f:
            json.dump(points, f)
        print("üíæ Fence saved.")
    except Exception as e:
        print("‚ö†Ô∏è Could not save fence:", e)

def load_fence():
    if os.path.exists(FENCE_FILE):
        try:
            with open(FENCE_FILE, "r") as f:
                data = json.load(f)
            if isinstance(data, list):
                print("‚úÖ Loaded saved fence.")
                return data
        except Exception as e:
            print("‚ö†Ô∏è Could not load fence:", e)
    return []

# ---------------- Camera & UI Setup ----------------
drawing = False
fence_points = load_fence()
temp_points = []

cap = cv2.VideoCapture(0)              # USB cam; if Pi camera, use libcamera approach
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

if not cap.isOpened():
    print("‚ùå Camera not opened")
    lgpio.gpiochip_close(chip)
    exit()

print("üé• Camera ready. Press 'f' to draw fence, Enter to save, 'r' to reset, 'q' to quit")

def mouse_callback(event, x, y, flags, param):
    global drawing, temp_points
    if drawing and event == cv2.EVENT_LBUTTONDOWN:
        temp_points.append((x, y))
        print("üü£ Point added:", x, y)

cv2.namedWindow("YOLOv8n Human Detection")
cv2.setMouseCallback("YOLOv8n Human Detection", mouse_callback)

# ---------------- FPS smoothing variables ----------------
fps = 0.0
alpha = 0.1   # smoothing factor (0..1) lower = smoother
last_time = time.time()

# ---------------- Main Loop ----------------
try:
    while True:
        ret, frame = cap.read()
        if not ret:
            print("‚ö†Ô∏è Frame not captured")
            time.sleep(0.05)
            continue

        # ---------------- timing / FPS ----------------
        now = time.time()
        dt = now - last_time
        last_time = now
        inst_fps = 1.0 / dt if dt > 0 else 0.0
        fps = (1 - alpha) * fps + alpha * inst_fps if fps > 0 else inst_fps

        # ---------------- draw existing fence ----------------
        if len(fence_points) > 1:
            cv2.polylines(frame, [np.array(fence_points, np.int32)], True, (255, 0, 255), 2)
            for (x, y) in fence_points:
                cv2.circle(frame, (x, y), 4, (255, 0, 255), -1)
        if drawing and len(temp_points) > 1:
            cv2.polylines(frame, [np.array(temp_points, np.int32)], False, (255, 0, 255), 2)

        # ---------------- inference with reduced size for speed ----------------
        # imgsz 416 balances speed & accuracy on Pi5
        results = model(frame, imgsz=416, verbose=False)[0]

        count = 0
        # Iterate detected boxes
        for box in results.boxes:
            # class index
            cls = int(box.cls[0])
            # skip non-person
            if model.names[cls] != "person":
                continue

            # get bbox (xyxy)
            # box.xyxy[0] is tensor-like; converting to ints works
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2

            inside_fence = False
            if len(fence_points) > 2:
                fence = np.array(fence_points, np.int32)

                # center inside?
                if cv2.pointPolygonTest(fence, (cx, cy), False) >= 0:
                    inside_fence = True
                else:
                    # check corners for touch/overlap
                    corners = [(x1, y1), (x2, y1), (x1, y2), (x2, y2)]
                    for c in corners:
                        if cv2.pointPolygonTest(fence, c, False) >= 0:
                            inside_fence = True
                            break

            if inside_fence:
                count += 1
                # RED for inside
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
                cv2.putText(frame, "Inside Fence", (x1, y1 - 8),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
            else:
                # GREEN for outside
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

        # ---------------- instant GPIO output ----------------
        lgpio.gpio_write(chip, GPIO_PIN, 0 if count > 0 else 1)

        # ---------------- overlay FPS & info ----------------
        cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
        cv2.putText(frame, f"Humans Inside: {count}", (10, 70),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)

        # send to stream
        with lock:
            output_frame = frame.copy()

        # show locally
        cv2.imshow("YOLOv8n Human Detection", frame)
        key = cv2.waitKey(1) & 0xFF

        if key == ord('f'):
            drawing = True
            temp_points = []
            print("üü£ Draw fence by clicking points")
        elif key == 13 and drawing:   # Enter to finalize
            fence_points = temp_points.copy()
            drawing = False
            save_fence(fence_points)
            print("‚úÖ Fence saved")
        elif key == ord('r'):
            fence_points = []
            temp_points = []
            drawing = False
            save_fence(fence_points)
            print("üîÅ Fence reset")
        elif key == ord('q'):
            break

finally:
    cap.release()
    cv2.destroyAllWindows()
    lgpio.gpio_write(chip, GPIO_PIN, 1)  # set HIGH on exit
    lgpio.gpiochip_close(chip)
    print("‚öôÔ∏è Clean exit")
